{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imageai.Detection import ObjectDetection\n",
    "# https://www.404bugs.com/details/1079375428891496448"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = ObjectDetection()\n",
    "detector.setModelTypeAsYOLOv3()\n",
    "detector.setModelPath(\"./model/yolov3.pt\")\n",
    "detector.loadModel()\n",
    "\n",
    "# COCO Name\n",
    "# 'person', 'bicycle', 'car', 'motorbike', 'bus', 'truck', 'traffic light', 'stop sign'\n",
    "target_objects = detector.CustomObjects(person=1, bicycle=1, car=1, motorbike=1, bus=1, \n",
    "                                        truck=1, traffic_light=1, stop_sign=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '000001',\n",
       " 'key_frame': '3.jpg',\n",
       " 'status': 0,\n",
       " 'frames': [{'frame_name': '1.jpg', 'gps_time': 1552212488},\n",
       "  {'frame_name': '2.jpg', 'gps_time': 1552212493},\n",
       "  {'frame_name': '3.jpg', 'gps_time': 1552212498},\n",
       "  {'frame_name': '4.jpg', 'gps_time': 1552212503}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"./data/\"\n",
    "result_path = \"./result/\"\n",
    "with open(f\"{data_path}/amap_traffic_annotations_train.json\", \"r\") as f:\n",
    "    train_json = json.load(f)\n",
    "train_json = train_json['annotations']\n",
    "with open(f\"{data_path}/amap_traffic_annotations_test.json\", \"r\") as f:\n",
    "    test_json = json.load(f)\n",
    "test_json = test_json['annotations']\n",
    "\n",
    "train_json[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_json\n",
    "folder_name = \"amap_traffic_train_0712\"\n",
    "detect_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [08:10<00:00,  3.06it/s]\n"
     ]
    }
   ],
   "source": [
    "for point in tqdm(data[:]):\n",
    "    map_id = point['id']\n",
    "    result = {}\n",
    "    result['id'] = map_id\n",
    "    temp = []\n",
    "    root_path = f\"{data_path}/{folder_name}/{map_id}/\"\n",
    "    # y_length, x_length, _ = cv.imread(root_path + f\"{point['key_frame']}\").shape\n",
    "    for _frame in point[\"frames\"]:\n",
    "        detect_result = detector.detectObjectsFromImage(input_image=root_path + f\"{_frame['frame_name']}\")\n",
    "        temp.append(detect_result)\n",
    "    result['frames'] = temp\n",
    "    detect_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./detect_results.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(detect_results, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat(n1, n2, data):\n",
    "    rate = 10\n",
    "    ty = n1\n",
    "    rl = []\n",
    "    for i in tqdm(data[:sample]):\n",
    "        iy, ix, _ = cv.imread(f\"{data_path}/{ty}/{i['id']}/{i['key_frame']}\").shape\n",
    "        r = {i:[None]*44 for i in range(-4, 4+1)}\n",
    "\n",
    "        for j in i[\"frames\"]:\n",
    "            det1 = detector.detectObjectsFromImage(input_image=f\"{data_path}/{ty}/{i['id']}/{j['frame_name']}\",minimum_percentage_probability=rate)\n",
    "            det2 = [[[_[\"percentage_probability\"]] + _[\"box_points\"]] for _ in det1 if _[\"name\"] == \"car\"]\n",
    "            if det2:\n",
    "                det3 = np.array(det2)\n",
    "\n",
    "                k = int(j[\"frame_name\"][0]) - int(i[\"key_frame\"][0])\n",
    "                r[k] = [\n",
    "                    len(det1),\n",
    "                    len(det2),\n",
    "                    \n",
    "                    np.max(det3[:,:,0]), \n",
    "                    np.min(det3[:,:,0]), \n",
    "                    np.max(det3[:,:,0])-np.min(det3[:,:,0]), \n",
    "                    np.max(det3[:,:,0])-np.mean(det3[:,:,0]), \n",
    "                    np.max(det3[:,:,0])-np.median(det3[:,:,0]), \n",
    "                    np.mean(det3[:,:,0])-np.median(det3[:,:,0]), \n",
    "                    np.mean(det3[:,:,0]), \n",
    "                    np.median(det3[:,:,0]),\n",
    "                    np.std(det3[:,:,0]),\n",
    "\n",
    "                    np.max(det3[:,:,1]), \n",
    "                    np.min(det3[:,:,1]), \n",
    "                    np.max(det3[:,:,1])-np.min(det3[:,:,1]),\n",
    "                    np.max(det3[:,:,1])-np.mean(det3[:,:,1]), \n",
    "                    np.max(det3[:,:,1])-np.median(det3[:,:,1]), \n",
    "                    np.mean(det3[:,:,1])-np.median(det3[:,:,1]), \n",
    "                    np.mean(det3[:,:,1]),\n",
    "                    np.median(det3[:,:,1]), \n",
    "                    np.std(det3[:,:,1]),\n",
    "                    \n",
    "                    np.max(det3[:,:,2]), \n",
    "                    np.min(det3[:,:,2]), \n",
    "                    np.max(det3[:,:,2])-np.min(det3[:,:,2]), \n",
    "                    np.max(det3[:,:,2])-np.mean(det3[:,:,2]), \n",
    "                    np.max(det3[:,:,2])-np.median(det3[:,:,2]), \n",
    "                    np.mean(det3[:,:,2])-np.median(det3[:,:,2]), \n",
    "                    np.mean(det3[:,:,2]), \n",
    "                    np.median(det3[:,:,2]), \n",
    "                    np.std(det3[:,:,2]),\n",
    "                    \n",
    "                    np.max(det3[:,:,3]), \n",
    "                    np.min(det3[:,:,3]), \n",
    "                    np.max(det3[:,:,3])-np.min(det3[:,:,3]), \n",
    "                    np.max(det3[:,:,3])-np.mean(det3[:,:,3]), \n",
    "                    np.max(det3[:,:,3])-np.median(det3[:,:,3]), \n",
    "                    np.mean(det3[:,:,3])-np.median(det3[:,:,3]), \n",
    "                    np.mean(det3[:,:,3]), \n",
    "                    np.median(det3[:,:,3]), \n",
    "                    np.std(det3[:,:,3]),\n",
    "                    \n",
    "                    np.max(det3[:,:,4]), \n",
    "                    np.min(det3[:,:,4]), \n",
    "                    np.max(det3[:,:,4])-np.min(det3[:,:,4]), \n",
    "                    np.max(det3[:,:,4])-np.mean(det3[:,:,4]), \n",
    "                    np.max(det3[:,:,4])-np.median(det3[:,:,4]), \n",
    "                    np.mean(det3[:,:,4])-np.median(det3[:,:,4]), \n",
    "                    np.mean(det3[:,:,4]), \n",
    "                    np.median(det3[:,:,4]), \n",
    "                    np.std(det3[:,:,4]),\n",
    "\n",
    "                    abs(np.max(det3[:,:,1])/ix-0.5), \n",
    "                    abs(np.min(det3[:,:,1])/ix-0.5), \n",
    "                    abs(np.mean(det3[:,:,1])/ix-0.5),\n",
    "                    abs(np.median(det3[:,:,1])/ix-0.5),\n",
    "                    \n",
    "                    abs(np.max(det3[:,:,2])/iy-0.5), \n",
    "                    abs(np.min(det3[:,:,2])/iy-0.5), \n",
    "                    abs(np.mean(det3[:,:,2])/iy-0.5),\n",
    "                    abs(np.median(det3[:,:,2])/iy-0.5),\n",
    "                    \n",
    "                    abs(np.max(det3[:,:,3])/ix-0.5), \n",
    "                    abs(np.min(det3[:,:,3])/ix-0.5), \n",
    "                    abs(np.mean(det3[:,:,3])/ix-0.5),\n",
    "                    abs(np.median(det3[:,:,3])/ix-0.5),\n",
    "                    \n",
    "                    abs(np.max(det3[:,:,4])/iy-0.5), \n",
    "                    abs(np.min(det3[:,:,4])/iy-0.5), \n",
    "                    abs(np.mean(det3[:,:,4])/iy-0.5),\n",
    "                    abs(np.median(det3[:,:,4])/iy-0.5),\n",
    "                    \n",
    "                    j[\"gps_time\"]\n",
    "                ]\n",
    "        rl.append([i[\"id\"], i[\"status\"]]+r[-4]+r[-3]+r[-2]+r[-1]+r[0]+r[1]+r[2]+r[3]+r[4])\n",
    "        # break\n",
    "\n",
    "    prl = pd.DataFrame(rl)\n",
    "    prl.to_pickle(f\"{data_path}/{n2}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat(n1=\"amap_traffic_train_0712\", n2=\"trai\", data=train_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prl = pd.read_pickle(f\"{data_path}/trai.pkl\")\n",
    "print(pd.value_counts(prl[1]))\n",
    "prl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prl.fillna(-999999, inplace=True)\n",
    "m_x = prl[prl.columns.drop([0, 1])]\n",
    "m_y = prl[1]\n",
    "\n",
    "X_trai, X_test, y_trai, y_test = train_test_split(m_x, m_y, test_size=0.30)\n",
    "print(X_trai.shape, X_test.shape, y_trai.shape, y_test.shape)\n",
    "\n",
    "import xgboost as xgb\n",
    "d_train = xgb.DMatrix(X_trai, label=y_trai)\n",
    "d_test = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 3,\n",
    "    'eval_metric': 'mlogloss',\n",
    "#     'max_depth': 6,\n",
    "#     'subsample': 0.75,\n",
    "#     'colsample_bytree': 0.75,\n",
    "#     'min_child_weight': 2,\n",
    "#     'eta': 0.1,\n",
    "#     'silent': 1,\n",
    "    'learning_rate': 0.001,\n",
    "}\n",
    "\n",
    "watchlist = [(d_train,'train'), (d_test, \"test\")]\n",
    "bst = xgb.train(params, d_train, num_boost_round=3600, evals=watchlist)\n",
    "bst.save_model(\"../outs/m001.model\")\n",
    "\n",
    "y_trai_p = bst.predict(xgb.DMatrix(X_trai))\n",
    "y_test_p = bst.predict(xgb.DMatrix(X_test))\n",
    "\n",
    "a_trai = metrics.accuracy_score(y_trai, y_trai_p)\n",
    "f_trai = metrics.f1_score(y_trai, y_trai_p, average='macro')\n",
    "a_test = metrics.accuracy_score(y_test, y_test_p)\n",
    "f_test = metrics.f1_score(y_test, y_test_p, average='macro')\n",
    "print(\">>> AC Train:%.6f, Tests:%.6f\" % (a_trai, a_test))\n",
    "print(\">>> F1 Train:%.6f, Tests:%.6f\" % (f_trai, f_test))\n",
    "# >>> F1 Train:0.963367, Tests:0.464979"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat(n1=\"amap_traffic_test_0712\", n2=\"test\", data=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prl = pd.read_pickle(f\"{dt}/test.pkl\")\n",
    "print(pd.value_counts(prl[1]))\n",
    "prl.fillna(-999999, inplace=True)\n",
    "prl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prl[\"score\"] = bst.predict(xgb.DMatrix(prl[prl.columns.drop([0, 1])]))\n",
    "print(pd.value_counts(prl[\"score\"]))\n",
    "prl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {\"annotations\": []}\n",
    "for i, j in zip(prl[0], prl[\"score\"]):\n",
    "    for _ in test[\"annotations\"]:\n",
    "        if _[\"id\"] == i:\n",
    "            _[\"status\"] = int(j)\n",
    "            result[\"annotations\"].append(_)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target = json.dumps(result, ensure_ascii=False)\n",
    "with open(f\"result/resultT001.json\", 'w') as f:\n",
    "    f.write(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
